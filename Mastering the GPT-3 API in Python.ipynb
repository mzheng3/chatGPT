{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aba72f7",
   "metadata": {},
   "source": [
    "GPT-3 ia a language machine-learning model that was released by OpenAI a couple of years ago. GPT-3 as an extension of the Generative Pre-training transformer uses self-attention and reinforcement learning to model conversational text. In general, it works by processing text one word at a time and it uses previous words to predict the next word in a sequence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e866b493",
   "metadata": {},
   "source": [
    "## Setting up GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4598ae4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (0.26.4)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from openai) (3.8.3)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from openai) (2.26.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from openai) (4.62.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from requests>=2.20->openai) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from requests>=2.20->openai) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from aiohttp->openai) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from aiohttp->openai) (21.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from tqdm->openai) (0.4.4)\n",
      "Requirement already satisfied: catboost in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\emily\\appdata\\roaming\\python\\python39\\site-packages (from catboost) (3.5.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from catboost) (5.7.0)\n",
      "Requirement already satisfied: six in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: graphviz in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from catboost) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from catboost) (1.20.3)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from catboost) (1.3.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from pandas>=0.24.0->catboost) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from matplotlib->catboost) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from matplotlib->catboost) (22.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from matplotlib->catboost) (3.0.4)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\emily\\anaconda3\\20220413installed\\lib\\site-packages (from plotly->catboost) (8.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a8c551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"your own openAI key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f29a1fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Pandas is a Python library designed for data manipulation and analysis. It provides a powerful data structure called a DataFrame that allows you to analyze and manipulate data in a way that is both intuitive and efficient. Pandas also provides efficient data analysis tools such as grouping, merging, and reshaping data, as well as visualizations for data exploration.\n"
     ]
    }
   ],
   "source": [
    "model_engine = \"text-davinci-003\"\n",
    "prompt = \"What is the pandas library?\"\n",
    "completion = openai.Completion.create(engine = model_engine,\n",
    "                                     prompt = prompt, max_tokens = 1024, \n",
    "                                     n = 1, stop = None, temperature = 0.7)\n",
    "message = completion.choices[0]['text']\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dc24707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Data Cleaning: Pandas is often used for cleaning messy data sets. It can help with data pre-processing and data wrangling tasks like filtering, sub-setting, and aggregating data.\n",
      "\n",
      "2. Data Analysis: Pandas is frequently used for exploratory data analysis and data visualization with tools like matplotlib, seaborn, and plotly.\n",
      "\n",
      "3. Time Series Analysis: Pandas is great for analyzing time-series data like stock prices, economic indicators, and sales data.\n",
      "\n",
      "4. Machine Learning: Pandas can be used for feature engineering and feature selection tasks required for machine learning models.\n"
     ]
    }
   ],
   "source": [
    "model_engine = \"text-davinci-003\"\n",
    "prompt = \"What are some common Pandas use cases?\"\n",
    "completion = openai.Completion.create(engine = model_engine,\n",
    "                                     prompt = prompt, max_tokens = 1024, \n",
    "                                     n = 1, stop = None, temperature = 0.7)\n",
    "message = completion.choices[0]['text']\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fbcff1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The most common deep learning libraries are TensorFlow, Keras, PyTorch, Caffe, Theano, MXNet, and Torch.\n"
     ]
    }
   ],
   "source": [
    "model_engine = \"text-davinci-003\"\n",
    "prompt = \"What are the most common deep learning libraries?\"\n",
    "completion = openai.Completion.create(engine = model_engine,\n",
    "                                     prompt = prompt, max_tokens = 1024, \n",
    "                                     n = 1, stop = None, temperature = 0.7)\n",
    "message = completion.choices[0]['text']\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5771f882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Data Cleaning: This involves detecting and correcting errors or inconsistencies in the data such as missing values, outliers, and inconsistent formats.\n",
      "\n",
      "2. Data Transformation: This involves converting data from one form to another such as normalizing, standardizing, and aggregating data.\n",
      "\n",
      "3. Data Reduction: This involves reducing the size of the data set by removing irrelevant features and combining similar features.\n",
      "\n",
      "4. Feature Extraction: This involves creating new features from existing ones to increase the predictive power of a model.\n",
      "\n",
      "5. Feature Selection: This involves selecting the most important features from the data set to simplify the model and improve its accuracy.\n"
     ]
    }
   ],
   "source": [
    "model_engine = \"text-davinci-003\"\n",
    "prompt = \"What are some data preprocessing techniques?\"\n",
    "completion = openai.Completion.create(engine = model_engine,\n",
    "                                     prompt = prompt, max_tokens = 1024, \n",
    "                                     n = 1, stop = None, temperature = 0.7)\n",
    "message = completion.choices[0]['text']\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55aabcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Linear SVM algorithm: This algorithm finds a linear separator in the given data set that distinguishes the classes by maximizing the margin. The algorithm solves a convex optimization problem to find the optimal hyperplane.\n",
      "\n",
      "2. Non-linear SVM algorithm: This algorithm uses the kernel trick to transform the data into a higher dimensional space in order to find a non-linear separator. The kernel trick is used to map data that is not linearly separable into a higher dimensional space in which it becomes linearly separable. \n",
      "\n",
      "3. Sequential Minimal Optimization (SMO) algorithm: This algorithm is an iterative method used to solve the quadratic optimization problem that arises from the SVM algorithm. It works by breaking down the large quadratic optimization problem into a series of smaller quadratic optimization problems, which can then be solved efficiently.\n",
      "\n",
      "4. Platt Scaling algorithm: This algorithm is a post-processing step used to calibrate the output of the SVM algorithm. It works by fitting a sigmoid function to the output of the SVM algorithm and then adjusting the parameters of the sigmoid function to optimize the accuracy of the classification.\n"
     ]
    }
   ],
   "source": [
    "model_engine = \"text-davinci-003\"\n",
    "prompt = \"Show me the algorithms of SVM?\"\n",
    "completion = openai.Completion.create(engine = model_engine,\n",
    "                                     prompt = prompt, max_tokens = 1024, \n",
    "                                     n = 1, stop = None, temperature = 0.7)\n",
    "message = completion.choices[0]['text']\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bb5aa9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Normalizing or standardizing data: Normalizing or standardizing data can help improve model performance by transforming the data into a more consistent format. This can help the model better interpret the data, as different features may be expressed in different scales.\n",
      "\n",
      "2. Feature engineering: Feature engineering can be a powerful way to improve model performance. This involves creating new features from existing data, or transforming existing features to better capture the relationships between the data points.\n",
      "\n",
      "3. Dimensionality reduction: Dimensionality reduction techniques such as Principal Component Analysis (PCA) can be used to reduce the number of features in a dataset, which can help improve model performance by reducing the complexity of the data.\n",
      "\n",
      "4. Data augmentation: Data augmentation is a technique which involves generating additional data points from existing data, with the aim of increasing the size and diversity of the dataset. This can help the model better learn the underlying patterns in the data.\n",
      "\n",
      "5. Imputation: Imputation is a technique which involves filling in missing values in a dataset. This can help improve model performance by ensuring that the model is not adversely affected by the presence of missing values.\n"
     ]
    }
   ],
   "source": [
    "model_engine = \"text-davinci-003\"\n",
    "prompt = \"Give some ideas on data transformation that can improve model performance\"\n",
    "completion = openai.Completion.create(engine = model_engine,\n",
    "                                     prompt = prompt, max_tokens = 1024, \n",
    "                                     n = 1, stop = None, temperature = 0.7)\n",
    "message = completion.choices[0]['text']\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ba8211c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Normalization: Normalizing the data by converting it into a common scale can improve model performance. This helps in reducing the dominance of one feature over others, thus allowing the model to make more accurate decisions.\n",
      "\n",
      "2. Outlier removal: Removing outliers from the data can help improve model performance by reducing the variance and increasing the accuracy of the model. \n",
      "\n",
      "3. Feature engineering: Generating new features from existing data can help the model learn more complex patterns and improve its performance.\n",
      "\n",
      "4. Dimensionality reduction: Reducing the number of feature variables can help reduce the complexity of the model and improve its performance.\n",
      "\n",
      "5. Imputation: Imputing missing values can help improve the accuracy of the model.\n",
      "\n",
      "6. Synthetic data generation: Generating additional data from existing data can help improve the accuracy of the model.\n"
     ]
    }
   ],
   "source": [
    "model_engine = \"text-davinci-003\"\n",
    "prompt = \"Give some ideas on data transformation that can improve model performance\"\n",
    "completion = openai.Completion.create(engine = model_engine,\n",
    "                                     prompt = prompt, max_tokens = 4086, \n",
    "                                     n = 1, stop = None, temperature = 0.7)\n",
    "message = completion.choices[0]['text']\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebb726c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#Using StandardScaler from scikit-learn\n",
      "\n",
      "#Import StandardScaler\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "#Create a scaler object\n",
      "scaler = StandardScaler()\n",
      "\n",
      "#Fit the scaler to the data\n",
      "scaler.fit(data)\n",
      "\n",
      "#Transform the data\n",
      "data_scaled = scaler.transform(data)\n"
     ]
    }
   ],
   "source": [
    "model_engine = \"text-davinci-003\"\n",
    "prompt = \"Write python codes to perform data standardization\"\n",
    "completion = openai.Completion.create(engine = model_engine,\n",
    "                                     prompt = prompt, max_tokens = 4089, ## max 4097\n",
    "                                     n = 1, stop = None, temperature = 0.7)\n",
    "message = completion.choices[0]['text']\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f7ded3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#Standardize the data using the mean and standard deviation\n",
      "\n",
      "#import the necessary libraries \n",
      "import numpy as np \n",
      "\n",
      "#create an array of data\n",
      "data = np.array([2, 4, 5, 8, 10]) \n",
      "\n",
      "#calculate the mean of the data\n",
      "mean = np.mean(data) \n",
      "\n",
      "#calculate the standard deviation of the data\n",
      "std = np.std(data)\n",
      "\n",
      "#standardize the data\n",
      "standardized_data = (data - mean) / std\n",
      "\n",
      "#print the standardized data\n",
      "print(standardized_data)\n"
     ]
    }
   ],
   "source": [
    "model_engine = \"text-davinci-003\"\n",
    "prompt = \"Write python codes to perform data standardization\"\n",
    "completion = openai.Completion.create(engine = model_engine,\n",
    "                                     prompt = prompt, max_tokens = 4089, ## max 4097\n",
    "                                     n = 1, stop = None, temperature = 0.7)\n",
    "message = completion.choices[0]['text']\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f6258b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Feature transformation is the process of transforming data from one form to another. It is used to improve the performance of predictive models by making the data more suitable for analysis and easier to interpret. Examples of feature transformation include normalization, scaling, standardization, discretization, and binning. Feature transformation can be used to transform input variables, output variables, or both. It can also be used to reduce the number of features in a dataset, for example by combining related features into one, or by transforming a continuous feature into a categorical one.\n"
     ]
    }
   ],
   "source": [
    "model_engine = \"text-davinci-003\"\n",
    "prompt = \"Feature transformation\"\n",
    "completion = openai.Completion.create(engine = model_engine,\n",
    "                                     prompt = prompt, max_tokens = 4089, ## max 4097\n",
    "                                     n = 1, stop = None, temperature = 0.7)\n",
    "message = completion.choices[0]['text']\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9604b4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "import numpy as np \n",
      "\n",
      "# Data before Normalization \n",
      "data = np.array([2.5, 0.3, 2.8, 1.1, 2.2, 1.5, 0.2 ]) \n",
      "\n",
      "# Normalize data \n",
      "normalized_data = (data - np.min(data)) / (np.max(data) - np.min(data)) \n",
      "\n",
      "# Print normalized data \n",
      "print(normalized_data)\n"
     ]
    }
   ],
   "source": [
    "model_engine = \"text-davinci-003\"\n",
    "prompt = \"Python Code on Data normalization\"\n",
    "completion = openai.Completion.create(engine = model_engine,\n",
    "                                     prompt = prompt, max_tokens = 4091, ## max 4097\n",
    "                                     n = 1, stop = None, temperature = 0.7)\n",
    "message = completion.choices[0]['text']\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "476f3fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# importing necessary libraries\n",
      "import numpy as np \n",
      "import pandas as pd\n",
      "from sklearn import preprocessing\n",
      "\n",
      "# load the dataset\n",
      "df = pd.read_csv('data.csv') \n",
      "\n",
      "# features\n",
      "X=df.iloc[:,:-1].values\n",
      "\n",
      "# label\n",
      "y=df.iloc[:,-1].values\n",
      "\n",
      "# data scaling\n",
      "scaler = preprocessing.MinMaxScaler(feature_range = (0, 1)) \n",
      "X_after_scaling = scaler.fit_transform(X) \n",
      "\n",
      "# display the result\n",
      "print (X_after_scaling)\n"
     ]
    }
   ],
   "source": [
    "model_engine = \"text-davinci-003\"\n",
    "prompt = \"Python Code on Data scaling\"\n",
    "completion = openai.Completion.create(engine = model_engine,\n",
    "                                     prompt = prompt, max_tokens = 4091, ## max 4097\n",
    "                                     n = 1, stop = None, temperature = 0.7)\n",
    "message = completion.choices[0]['text']\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d439c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
